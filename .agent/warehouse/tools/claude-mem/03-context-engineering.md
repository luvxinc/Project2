# Claude-Mem 上下文工程参考

> **加载时机**: 需要优化 Agent 上下文效率、设计记忆检索策略时

## 1. 核心原则

> **找到最小的高信噪集合, 最大化期望结果的概率。**

```
上下文工程 ≠ Prompt Engineering (一次性)
上下文工程 = 每次推理时, 迭代地管理 token 集合

管理对象:
  - 系统指令
  - 工具定义
  - MCP 协议
  - 外部数据
  - 消息历史
  - 运行时数据检索
```

## 2. 上下文腐败 (Context Rot)

```
关键洞察: LLM 有 "注意力预算", 随上下文增长而耗尽

原因:
  - 每个 token 与每个其他 token 形成 n² 关系
  - 上下文越长, 模型准确度越低
  - 模型对长序列的训练经验更少
  - 后面的 token 获得的注意力少于前面的

结论: 上下文 = 有限资源, 边际收益递减
```

## 3. 系统 Prompt: 找到"正确高度"

### Goldilocks Zone

```
❌ 太具体:
  - 硬编码的 if-else 逻辑
  - 脆弱易碎
  - 高维护成本

❌ 太模糊:
  - 高层指导没有具体信号
  - 错误假设共享上下文
  - 缺乏可执行方向

✅ 刚好:
  - 足够具体, 能有效指导行为
  - 足够灵活, 提供强启发式
  - 完整描述期望行为的最小信息集
```

### 最佳实践

- 用简单直接的语言
- 按功能组织 (`<background>`, `<instructions>`, `## 工具指南`)
- 用 XML 标签或 Markdown 标题结构化
- 从最小 prompt 开始, 基于失败模式添加
- 最小 ≠ 短 (提供足够信息)

## 4. 工具设计原则

```
✅ 自包含: 每个工具一个清晰目的
✅ 容错: 优雅处理边界情况
✅ 极清晰: 用途无歧义
✅ Token 高效: 返回相关信息, 不膨胀
✅ 描述性参数: user_id 而非 user

关键规则:
  如果一个人类工程师无法确定该用哪个工具,
  AI Agent 也不会做得更好。

❌ 避免:
  - 膨胀的工具集 (功能过多)
  - 重叠的工具 (search_observations vs find_by_type)
  - 模糊的决策点

实例: claude-mem v5→v10 将 9 个工具压缩为 5 个核心 MCP 工具 (search/timeline/get_observations/save_memory/__IMPORTANT)
```

## 5. 上下文检索策略

### 策略 1: Just-In-Time 上下文 (推荐)

```
方法: 维护轻量标识符 (路径/查询/链接), 运行时动态加载

优势:
  - 避免上下文污染
  - 支持渐进披露
  - 模仿人类认知 (我们不记住一切)
  - 利用元数据 (文件名, 目录结构, 时间戳)
  - Agent 增量发现上下文

代价:
  - 比预计算慢
  - 需要工具引导避免死胡同

→ 我们的系统: L0→L1→L2 三级检索 = Just-In-Time
```

### 策略 2: Pre-Inference 检索 (传统 RAG)

```
方法: 嵌入向量检索, 推理前加载
适用: 静态内容, 不变化的参考资料

→ 我们的系统: Spec/Reference 文件 = Pre-Inference
```

### 策略 3: Hybrid (最佳)

```
方法: 预加载部分数据, 按需自主探索
示例: Claude Code 预加载 CLAUDE.md, 用 glob/grep 按需检索

原则: "做最简单有效的事"

→ 我们的系统: SKILL.md 预加载 + 域索引按需 = Hybrid
```

## 6. 长任务三大技术

### 技术 1: 压缩 (Compaction)

```
场景: 接近上下文极限的对话
方法: 
  1. 将消息历史发送给模型压缩
  2. 保留关键决策/bug/实现细节
  3. 丢弃冗余输出
  4. 用压缩结果 + 最近访问文件继续

调优顺序:
  1. 先最大化召回 (不漏)
  2. 再提高精度 (去冗余)

低成本优化: 清理旧 tool call 和 result

→ 对应: handoff.md 的 Checkpoint 压缩
```

### 技术 2: 结构化笔记 (Agentic Memory)

```
场景: 跨步骤的持续任务
方法: Agent 写笔记到上下文窗口外, 后续取回

示例:
  - To-do 列表
  - NOTES.md 文件
  - 项目进度日志
  - 游戏状态追踪 (跟踪 1,234 步训练)

→ 对应: TRACKER-{task-id}.md + 进度日志
```

### 技术 3: Sub-Agent 架构

```
场景: 复杂研究和分析
方法:
  - 主 Agent 协调高层计划
  - 子 Agent 执行深度技术任务
  - 子 Agent 大量探索 (数万 token)
  - 返回浓缩摘要 (1,000-2,000 token)

→ 对应: PM/CTO/工程师 角色分工
```

## 7. 渐进披露: 完整设计理念

### 三层架构

```
Layer 1 (索引): "有什么?" 
  轻量元数据: 标题/日期/类型/token 成本
  成本: ~50 token/条
  决策: 停止 或 继续

Layer 2 (详情): "相关内容"
  完整内容, 仅限已验证相关的
  成本: ~500 token/条
  决策: 停止 或 深入

Layer 3 (源码): "原始数据"
  原始文件/代码/完整日志
  成本: 可变 (可能很大)
  仅在 L1+L2 确认后使用
```

### 对比

```
❌ 传统 (全量):
  Session Start → 加载 35,000 token → 6% 相关 → 94% 浪费
  
✅ 渐进披露:
  Session Start → 索引 1,000 token →
  Agent 判断: "#2543 相关!" →
  获取 #2543: 120 token →
  总计: 1,120 token → 100% 相关
```

### 上下文即货币

```
全量加载 = 把全部工资买可能需要的杂货 → 浪费
什么都不加载 = 拒绝花一分钱 → 饿死
渐进披露 = 查冰箱, 列清单, 只买需要的 → 高效
```

## 8. Anti-Patterns (避免)

```
❌ 塞满所有内容到 prompt
❌ 创建脆弱的 if-else 逻辑
❌ 构建膨胀的工具集
❌ 堆砌穷举的边界案例
❌ 假设更大上下文窗口能解决一切
❌ 忽略长交互中的上下文污染
```

## 9. 决策框架

| 场景 | 推荐策略 |
|------|---------|
| 静态参考内容 | Pre-inference / Hybrid |
| 需要动态探索 | Just-In-Time |
| 长对话/接近极限 | Compaction |
| 迭代开发/多步骤 | Structured Note-Taking |
| 复杂研究/分析 | Sub-Agent 架构 |
| 不确定时 | "做最简单有效的事" |

## 10. 我们系统已实现的对应

| 上下文工程原理 | 我们的实现 | 状态 |
|---------------|----------|------|
| Just-In-Time 检索 | L0→L1→L2 三级路由 | ✅ 已实现 |
| 渐进披露 | SKILL.md → domains/*.md → skills/*.md §N | ✅ 已实现 |
| 结构化笔记 | TRACKER + 进度日志 | ✅ 已实现 |
| 压缩/Checkpoint | handoff.md Checkpoint 协议 | ✅ 已实现 |
| Sub-Agent | PM/CTO/工程师/QA 角色分工 | ✅ 已实现 |
| Anti-pattern 避免 | memory.md §5 上下文约束 | ✅ 已实现 |
| 工具设计原则 | SOP 路由表 + L3 工具引用 | ✅ 已实现 |
| Token 成本可见化 | ❌ 未实现 | 📋 可借鉴 |
| 观察类型分类 | ❌ 未实现 | 📋 可借鉴 |
| 自动 Hook 捕获 | ❌ 手工更新 TRACKER | 📋 可借鉴 |
