#!/usr/bin/env python3
"""
ä¼ä¸šçº§ i18n å®Œæ•´æ€§å®¡è®¡è„šæœ¬
Enterprise-Grade Internationalization Audit Script

å®¡è®¡èŒƒå›´:
1. åç«¯ Python (JsonResponse/HttpResponse ä¸­çš„ç¡¬ç¼–ç ä¸­æ–‡)
2. å‰ç«¯ HTML æ¨¡æ¿ ({% trans %} æ ‡ç­¾åŠ è½½æ£€æŸ¥)
3. JavaScript (alert/confirm ç¡¬ç¼–ç æ£€æŸ¥)
4. ç¿»è¯‘æ–‡ä»¶å®Œæ•´æ€§ (zh.json vs en.json é”®å€¼å¯¹é½)
5. é—æ¼çš„ gettext å¯¼å…¥

æ‰§è¡Œ: python3 aid/audit/enterprise_i18n_audit.py
"""

import os
import re
import json
from pathlib import Path
from collections import defaultdict

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent.parent
BACKEND_DIR = PROJECT_ROOT / 'backend'
APPS_DIR = BACKEND_DIR / 'apps'
TEMPLATES_DIR = BACKEND_DIR / 'templates'
STATIC_DIR = BACKEND_DIR / 'static'
I18N_DIR = STATIC_DIR / 'i18n'

# ä¸­æ–‡å­—ç¬¦æ­£åˆ™
CHINESE_REGEX = re.compile(r'[\u4e00-\u9fff]')

# å®¡è®¡ç»“æœ
audit_results = {
    'backend_hardcoded': [],      # åç«¯ç¡¬ç¼–ç ä¸­æ–‡
    'template_missing_load': [],  # æ¨¡æ¿æœªåŠ è½½ i18n
    'template_trans_usage': [],   # æ¨¡æ¿ä½¿ç”¨ trans ä½†å¯èƒ½æœªåŠ è½½
    'js_hardcoded': [],           # JS ç¡¬ç¼–ç ä¸­æ–‡
    'translation_mismatch': [],   # ç¿»è¯‘é”®ä¸åŒ¹é…
    'missing_gettext_import': [], # ç¼ºå°‘ gettext å¯¼å…¥
    'backup_files': [],           # å¤‡ä»½æ–‡ä»¶æ®‹ç•™
}

stats = {
    'py_files_scanned': 0,
    'html_files_scanned': 0,
    'js_files_scanned': 0,
    'total_issues': 0,
}


def scan_python_files():
    """æ‰«æ Python æ–‡ä»¶ä¸­çš„ç¡¬ç¼–ç ä¸­æ–‡"""
    print("\n[1/6] æ‰«æåç«¯ Python æ–‡ä»¶...")
    
    # éœ€è¦æ£€æŸ¥çš„æ¨¡å¼
    patterns = [
        (r"JsonResponse\s*\(\s*\{[^}]*['\"][^'\"]*[\u4e00-\u9fff]+", "JsonResponse ç¡¬ç¼–ç "),
        (r"HttpResponse\s*\([^)]*[\u4e00-\u9fff]+", "HttpResponse ç¡¬ç¼–ç "),
        (r"['\"](message|error|msg)['\"]:\s*['\"][^'\"]*[\u4e00-\u9fff]+", "æ¶ˆæ¯å­—æ®µç¡¬ç¼–ç "),
    ]
    
    for py_file in APPS_DIR.rglob('*.py'):
        if '.bak' in str(py_file) or '__pycache__' in str(py_file):
            if '.bak' in str(py_file):
                audit_results['backup_files'].append(str(py_file))
            continue
            
        stats['py_files_scanned'] += 1
        
        try:
            content = py_file.read_text(encoding='utf-8')
            lines = content.split('\n')
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ gettext å¯¼å…¥
            has_gettext = 'from django.utils.translation import' in content or 'gettext' in content
            uses_underscore = re.search(r"_\s*\(['\"]", content)
            
            for i, line in enumerate(lines, 1):
                # è·³è¿‡æ³¨é‡Šå’Œæ–‡æ¡£å­—ç¬¦ä¸²
                stripped = line.strip()
                if stripped.startswith('#') or stripped.startswith('"""') or stripped.startswith("'''"):
                    continue
                
                # æ£€æŸ¥ JsonResponse/HttpResponse ä¸­çš„ä¸­æ–‡
                for pattern, desc in patterns:
                    if re.search(pattern, line):
                        # æ£€æŸ¥æ˜¯å¦å·²ç”¨ _() åŒ…è£¹
                        if not re.search(r"_\s*\(['\"]", line):
                            audit_results['backend_hardcoded'].append({
                                'file': str(py_file.relative_to(PROJECT_ROOT)),
                                'line': i,
                                'type': desc,
                                'content': line.strip()[:100]
                            })
                            
            # æ£€æŸ¥ä½¿ç”¨äº† _() ä½†æœªå¯¼å…¥ gettext
            if uses_underscore and not has_gettext:
                audit_results['missing_gettext_import'].append(str(py_file.relative_to(PROJECT_ROOT)))
                
        except Exception as e:
            print(f"  âš ï¸ æ— æ³•è¯»å–: {py_file} - {e}")


def scan_templates():
    """æ‰«æ HTML æ¨¡æ¿æ–‡ä»¶"""
    print("\n[2/6] æ‰«æå‰ç«¯ HTML æ¨¡æ¿...")
    
    for html_file in TEMPLATES_DIR.rglob('*.html'):
        if '.bak' in str(html_file):
            audit_results['backup_files'].append(str(html_file))
            continue
            
        stats['html_files_scanned'] += 1
        
        try:
            content = html_file.read_text(encoding='utf-8')
            
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº† {% trans %} æ ‡ç­¾
            uses_trans = '{% trans' in content or '{% blocktrans' in content
            
            # æ£€æŸ¥æ˜¯å¦åŠ è½½äº† i18n
            has_load_i18n = '{% load i18n' in content or "{% load 'i18n'" in content
            
            # å¦‚æœä½¿ç”¨äº† trans ä½†æ²¡æœ‰åŠ è½½ i18n
            if uses_trans and not has_load_i18n:
                # æ£€æŸ¥æ˜¯å¦ç»§æ‰¿äº†åŸºç¡€æ¨¡æ¿ï¼ˆåŸºç¡€æ¨¡æ¿å¯èƒ½å·²åŠ è½½ï¼‰
                extends_base = '{% extends' in content
                if not extends_base:
                    audit_results['template_missing_load'].append({
                        'file': str(html_file.relative_to(PROJECT_ROOT)),
                        'reason': 'ä½¿ç”¨äº† trans æ ‡ç­¾ä½†æœªåŠ è½½ i18n'
                    })
                else:
                    # ç»§æ‰¿äº†æ¨¡æ¿ï¼Œæ£€æŸ¥çˆ¶æ¨¡æ¿
                    audit_results['template_trans_usage'].append({
                        'file': str(html_file.relative_to(PROJECT_ROOT)),
                        'note': 'ç»§æ‰¿æ¨¡æ¿ï¼Œéœ€ç¡®è®¤çˆ¶æ¨¡æ¿å·²åŠ è½½ i18n'
                    })
                    
        except Exception as e:
            print(f"  âš ï¸ æ— æ³•è¯»å–: {html_file} - {e}")


def scan_javascript():
    """æ‰«æ JavaScript æ–‡ä»¶ä¸­çš„ç¡¬ç¼–ç ä¸­æ–‡"""
    print("\n[3/6] æ‰«æ JavaScript æ–‡ä»¶...")
    
    # æ’é™¤çš„ç›®å½•
    exclude_dirs = {'vendor', 'lib', 'plugins', 'node_modules'}
    
    for js_file in STATIC_DIR.rglob('*.js'):
        if any(exc in str(js_file) for exc in exclude_dirs):
            continue
            
        stats['js_files_scanned'] += 1
        
        try:
            content = js_file.read_text(encoding='utf-8')
            lines = content.split('\n')
            
            for i, line in enumerate(lines, 1):
                # è·³è¿‡æ³¨é‡Š
                if line.strip().startswith('//'):
                    continue
                    
                # æ£€æŸ¥ alert/confirm ä¸­çš„ä¸­æ–‡
                if re.search(r"(alert|confirm)\s*\([^)]*[\u4e00-\u9fff]+", line):
                    if 'i18n.t(' not in line and "{% trans" not in line:
                        audit_results['js_hardcoded'].append({
                            'file': str(js_file.relative_to(PROJECT_ROOT)),
                            'line': i,
                            'content': line.strip()[:100]
                        })
                        
        except Exception as e:
            print(f"  âš ï¸ æ— æ³•è¯»å–: {js_file} - {e}")


def scan_embedded_js_in_templates():
    """æ‰«æåµŒå…¥åœ¨ HTML æ¨¡æ¿ä¸­çš„ JavaScript"""
    print("\n[4/6] æ‰«ææ¨¡æ¿å†…åµŒ JavaScript...")
    
    for html_file in TEMPLATES_DIR.rglob('*.html'):
        if '.bak' in str(html_file):
            continue
            
        try:
            content = html_file.read_text(encoding='utf-8')
            
            # æŸ¥æ‰¾ <script> æ ‡ç­¾å†…å®¹
            script_blocks = re.findall(r'<script[^>]*>(.*?)</script>', content, re.DOTALL)
            
            for block in script_blocks:
                lines = block.split('\n')
                for i, line in enumerate(lines, 1):
                    # æ£€æŸ¥ alert/confirm ä¸­çš„ä¸­æ–‡ï¼ˆæœªå›½é™…åŒ–ï¼‰
                    if re.search(r"(alert|confirm)\s*\(['\"][^'\"]*[\u4e00-\u9fff]+", line):
                        if "{% trans" not in line and "i18n.t(" not in line:
                            audit_results['js_hardcoded'].append({
                                'file': str(html_file.relative_to(PROJECT_ROOT)),
                                'line': f"script block",
                                'content': line.strip()[:100]
                            })
                            
        except Exception as e:
            pass


def verify_translation_files():
    """éªŒè¯ç¿»è¯‘æ–‡ä»¶å®Œæ•´æ€§"""
    print("\n[5/6] éªŒè¯ç¿»è¯‘æ–‡ä»¶å®Œæ•´æ€§...")
    
    zh_file = I18N_DIR / 'zh.json'
    en_file = I18N_DIR / 'en.json'
    
    if not zh_file.exists() or not en_file.exists():
        print("  âš ï¸ ç¿»è¯‘æ–‡ä»¶ä¸å­˜åœ¨")
        return
        
    try:
        zh_data = json.loads(zh_file.read_text(encoding='utf-8'))
        en_data = json.loads(en_file.read_text(encoding='utf-8'))
        
        def get_all_keys(d, prefix=''):
            """é€’å½’è·å–æ‰€æœ‰é”®"""
            keys = set()
            for k, v in d.items():
                full_key = f"{prefix}.{k}" if prefix else k
                if isinstance(v, dict):
                    keys.update(get_all_keys(v, full_key))
                else:
                    keys.add(full_key)
            return keys
            
        zh_keys = get_all_keys(zh_data)
        en_keys = get_all_keys(en_data)
        
        # æ‰¾å‡ºä¸åŒ¹é…çš„é”®
        only_in_zh = zh_keys - en_keys
        only_in_en = en_keys - zh_keys
        
        if only_in_zh:
            audit_results['translation_mismatch'].append({
                'type': 'ä»…åœ¨ zh.json ä¸­å­˜åœ¨',
                'keys': list(only_in_zh)[:10]  # åªæ˜¾ç¤ºå‰10ä¸ª
            })
            
        if only_in_en:
            audit_results['translation_mismatch'].append({
                'type': 'ä»…åœ¨ en.json ä¸­å­˜åœ¨',
                'keys': list(only_in_en)[:10]
            })
            
        print(f"  âœ… zh.json: {len(zh_keys)} é”®")
        print(f"  âœ… en.json: {len(en_keys)} é”®")
        if only_in_zh or only_in_en:
            print(f"  âš ï¸ ä¸åŒ¹é…: zhç‹¬æœ‰ {len(only_in_zh)}, enç‹¬æœ‰ {len(only_in_en)}")
        else:
            print(f"  âœ… é”®å€¼å®Œå…¨å¯¹é½")
            
    except json.JSONDecodeError as e:
        print(f"  âŒ JSON è§£æé”™è¯¯: {e}")


def cleanup_backup_files():
    """åˆ—å‡ºéœ€è¦æ¸…ç†çš„å¤‡ä»½æ–‡ä»¶"""
    print("\n[6/6] æ£€æŸ¥å¤‡ä»½æ–‡ä»¶æ®‹ç•™...")
    
    for backup in APPS_DIR.rglob('*.bak'):
        audit_results['backup_files'].append(str(backup.relative_to(PROJECT_ROOT)))
        
    for backup in TEMPLATES_DIR.rglob('*.bak'):
        audit_results['backup_files'].append(str(backup.relative_to(PROJECT_ROOT)))


def generate_report():
    """ç”Ÿæˆå®¡è®¡æŠ¥å‘Š"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ ä¼ä¸šçº§ i18n å®¡è®¡æŠ¥å‘Š")
    print("=" * 60)
    
    total_issues = 0
    
    # 1. åç«¯ç¡¬ç¼–ç 
    print(f"\nğŸ”´ åç«¯ç¡¬ç¼–ç ä¸­æ–‡: {len(audit_results['backend_hardcoded'])} å¤„")
    for item in audit_results['backend_hardcoded'][:5]:
        print(f"   - {item['file']}:{item['line']}")
        print(f"     {item['content'][:80]}...")
    if len(audit_results['backend_hardcoded']) > 5:
        print(f"   ... åŠå…¶ä»– {len(audit_results['backend_hardcoded']) - 5} å¤„")
    total_issues += len(audit_results['backend_hardcoded'])
    
    # 2. æ¨¡æ¿æœªåŠ è½½ i18n
    print(f"\nğŸŸ¡ æ¨¡æ¿æœªåŠ è½½ i18n: {len(audit_results['template_missing_load'])} å¤„")
    for item in audit_results['template_missing_load'][:5]:
        print(f"   - {item['file']}: {item['reason']}")
    total_issues += len(audit_results['template_missing_load'])
    
    # 3. JS ç¡¬ç¼–ç 
    print(f"\nğŸŸ¡ JavaScript ç¡¬ç¼–ç : {len(audit_results['js_hardcoded'])} å¤„")
    for item in audit_results['js_hardcoded'][:5]:
        print(f"   - {item['file']}:{item['line']}")
    if len(audit_results['js_hardcoded']) > 5:
        print(f"   ... åŠå…¶ä»– {len(audit_results['js_hardcoded']) - 5} å¤„")
    total_issues += len(audit_results['js_hardcoded'])
    
    # 4. ç¿»è¯‘ä¸åŒ¹é…
    print(f"\nğŸŸ¡ ç¿»è¯‘é”®ä¸åŒ¹é…: {len(audit_results['translation_mismatch'])} ç±»")
    for item in audit_results['translation_mismatch']:
        print(f"   - {item['type']}: {item['keys'][:3]}...")
    total_issues += len(audit_results['translation_mismatch'])
    
    # 5. ç¼ºå°‘ gettext å¯¼å…¥
    print(f"\nğŸŸ  ç¼ºå°‘ gettext å¯¼å…¥: {len(audit_results['missing_gettext_import'])} æ–‡ä»¶")
    for item in audit_results['missing_gettext_import'][:5]:
        print(f"   - {item}")
    total_issues += len(audit_results['missing_gettext_import'])
    
    # 6. å¤‡ä»½æ–‡ä»¶
    print(f"\nğŸ”µ å¤‡ä»½æ–‡ä»¶æ®‹ç•™: {len(audit_results['backup_files'])} ä¸ª")
    for item in audit_results['backup_files'][:5]:
        print(f"   - {item}")
    
    # ç»Ÿè®¡
    print("\n" + "-" * 60)
    print("ğŸ“Š å®¡è®¡ç»Ÿè®¡")
    print("-" * 60)
    print(f"   Python æ–‡ä»¶æ‰«æ: {stats['py_files_scanned']}")
    print(f"   HTML æ¨¡æ¿æ‰«æ: {stats['html_files_scanned']}")
    print(f"   JavaScript æ‰«æ: {stats['js_files_scanned']}")
    print(f"   æ€»é—®é¢˜æ•°: {total_issues}")
    
    # è¯„çº§
    print("\n" + "=" * 60)
    if total_issues == 0:
        print("ğŸ† å®¡è®¡ç»“æœ: âœ… PASS (å…¨éƒ¨é€šè¿‡)")
    elif total_issues <= 5:
        print("ğŸ“ å®¡è®¡ç»“æœ: ğŸŸ¡ MINOR ISSUES (è½»å¾®é—®é¢˜)")
    elif total_issues <= 20:
        print("âš ï¸ å®¡è®¡ç»“æœ: ğŸŸ  NEEDS ATTENTION (éœ€è¦å…³æ³¨)")
    else:
        print("âŒ å®¡è®¡ç»“æœ: ğŸ”´ CRITICAL (ä¸¥é‡é—®é¢˜)")
    print("=" * 60)
    
    return total_issues


def main():
    print("=" * 60)
    print("ğŸ” MGMT ERP ä¼ä¸šçº§ i18n å®¡è®¡")
    print(f"   é¡¹ç›®è·¯å¾„: {PROJECT_ROOT}")
    print("=" * 60)
    
    scan_python_files()
    scan_templates()
    scan_javascript()
    scan_embedded_js_in_templates()
    verify_translation_files()
    cleanup_backup_files()
    
    total_issues = generate_report()
    
    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    report_file = PROJECT_ROOT / 'aid' / 'audit' / 'i18n_enterprise_audit_report.json'
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(audit_results, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    return total_issues


if __name__ == '__main__':
    main()
