# core/services/database_service.py
"""
æ–‡ä»¶è¯´æ˜Ž: æ•°æ®åº“ç”Ÿå‘½å‘¨æœŸç®¡ç†æœåŠ¡ (Database Service) - Fix DateTime Parsing
ä¸»è¦åŠŸèƒ½:
1. å¤‡ä»½ç®¡ç† (Backup/Restore).
2. [Fix] æ–‡ä»¶åè§£æž: ä¿®æ­£ datetime è°ƒç”¨é”™è¯¯ï¼Œç¡®ä¿èƒ½æ­£ç¡®æ˜¾ç¤º 'ðŸ•’ æ—¶é—´ | ðŸ·ï¸ å¤‡æ³¨'ã€‚
3. æ•°æ®æ¸…æ´—ä¸Žå®¡è®¡ (è¡¨åè„±æ•)ã€‚
"""

import os
import subprocess
import datetime
import shutil
import pandas as pd
from pathlib import Path
from typing import List, Tuple, Callable, Optional
from sqlalchemy import text

from common.settings import settings
from core.components.db.client import DBClient
from core.sys.logger import get_logger, get_audit_logger
from core.sys.context import get_current_user

IMMUTABLE_MARKER = "[[SECURITY_AUDIT]]"

# =========================================================================
# æ ¸å¿ƒä¸šåŠ¡è¡¨åˆ—è¡¨ (24 ä¸ª in_ ç³»åˆ—è¡¨ - åŒ…å« FIFO 4è¡¨)
# è¿™æ˜¯ç³»ç»Ÿçš„"Source of Truth"ï¼Œé»˜è®¤å¤‡ä»½è¿™äº›è¡¨
# =========================================================================
CORE_TABLES = [
    # ä¾›åº”å•†ç®¡ç†
    "in_supplier",
    "in_supplier_strategy",
    # é‡‡è´­è®¢å•
    "in_po",
    "in_po_final",
    "in_po_strategy",
    # å‘è´§å•
    "in_send",
    "in_send_final",
    "in_send_list",
    # å…¥åº“
    "in_receive",
    "in_receive_final",
    # å…¥åº“å¼‚å¸¸
    "in_diff",
    "in_diff_final",
    # ä»˜æ¬¾ - ç‰©æµ
    "in_pmt_logistic",
    "in_pmt_logistic_final",
    # ä»˜æ¬¾ - å®šé‡‘
    "in_pmt_deposit",
    "in_pmt_deposit_final",
    # ä»˜æ¬¾ - è®¢å•
    "in_pmt_po",
    "in_pmt_po_final",
    # ä»˜æ¬¾ - é¢„ä»˜æ¬¾
    "in_pmt_prepay",
    "in_pmt_prepay_final",
    # FIFO åŠ¨æ€åº“å­˜ (4è¡¨)
    "in_dynamic_tran",
    "in_dynamic_fifo_layers",
    "in_dynamic_fifo_alloc",
    "in_dynamic_landed_price",
]


class DatabaseService:

    def __init__(self):
        self.logger = get_logger("DatabaseService")
        self.audit_logger = get_audit_logger()
        self.db = DBClient()

        self.host = settings.DB_HOST
        self.port = settings.DB_PORT
        self.user = settings.DB_USER
        self.password = settings.DB_PASS
        self.db_name = settings.DB_NAME

        self.backup_dir = settings.DB_BACKUP_DIR
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        
    def _update_progress(self, key: str, percent: float, status: str = ""):
        from django.core.cache import cache
        cache.set(f"db_task_{key}", {"percent": percent, "status": status}, timeout=300)

    # =========================================================================
    # [Fix] æ–‡ä»¶åè§£æžé€»è¾‘ (å…³é”®ä¿®å¤)
    # =========================================================================
    @staticmethod
    def parse_filename_to_display(filename: str) -> str:
        """
        Input:  20251209_175224_Init_Backup.sql
        Output: ðŸ•’ 2025-12-09 17:52:24 | ðŸ·ï¸ Init_Backup
        """
        try:
            # 1. åŽ»æŽ‰è·¯å¾„å’ŒåŽç¼€
            clean_name = os.path.basename(filename)
            if clean_name.lower().endswith('.sql'):
                clean_name = clean_name[:-4]

            # 2. åˆ†å‰² (æœ€å¤šåˆ†å‰²2æ¬¡: Date, Time, Rest)
            parts = clean_name.split("_", 2)

            if len(parts) >= 2:
                date_part = parts[0]  # 20251209
                time_part = parts[1]  # 175224
                tag_part = parts[2] if len(parts) > 2 else ""  # Init_Backup

                # 3. æ ¡éªŒæ•°å­—æ ¼å¼
                if len(date_part) == 8 and len(time_part) == 6 and date_part.isdigit() and time_part.isdigit():
                    # [Fix] ä½¿ç”¨ datetime.datetime.strptime
                    dt_obj = datetime.datetime.strptime(f"{date_part}{time_part}", "%Y%m%d%H%M%S")
                    dt_str = dt_obj.strftime("%Y-%m-%d %H:%M:%S")

                if tag_part:
                    return f"{dt_str} | {tag_part}"
                else:
                    return f"{dt_str}"
        except Exception:
            pass

        # è§£æžå¤±è´¥å…œåº•
        return f"{filename}"

    # --- Backup & Restore Logic ---
    def list_backups(self) -> List[str]:
        # Only list files in the main backup directory, ignoring usage of glob which might find nested ones if pattern changed
        # Use glob but explicitly just .sql in backup_dir
        return sorted([f.name for f in self.backup_dir.glob("*.sql") if f.is_file()], reverse=True)

    def _find_binary(self, name: str) -> str:
        """Helper to find mysql/mysqldump binary in common locations."""
        # 1. Try PATH
        path = shutil.which(name)
        if path: return path
        
        # 2. Try Standard Locations (Mac commonly in /usr/local/bin or /opt/homebrew/bin)
        common_paths = [
            f"/usr/local/bin/{name}",
            f"/usr/local/mysql/bin/{name}",
            f"/opt/homebrew/bin/{name}",
            f"/usr/bin/{name}",
            f"/sbin/{name}"
        ]
        
        for p in common_paths:
            if os.path.exists(p) and os.access(p, os.X_OK):
                return p
                
        return name  # Fallback to name (let subprocess fail naturally)



    def create_backup(self, tag: str = "", task_key: str = None, tables: List[str] = None, full_db: bool = False) -> Tuple[bool, str]:
        """
        Create Database Backup.
        
        Args:
            tag: å¤‡ä»½æ ‡ç­¾
            task_key: ä»»åŠ¡è¿›åº¦ key
            tables: å¤‡ä»½è¡¨åˆ—è¡¨ï¼ˆé»˜è®¤å¤‡ä»½ CORE_TABLESï¼‰
            full_db: æ˜¯å¦å¤‡ä»½å…¨åº“ï¼ˆè¦†ç›– tables å‚æ•°ï¼‰
        
        Note:
            é»˜è®¤è¡Œä¸ºå˜æ›´ï¼šçŽ°åœ¨é»˜è®¤å¤‡ä»½ 24 ä¸ªæ ¸å¿ƒ in_ è¡¨ï¼ˆåŒ…å« FIFO 4è¡¨ï¼‰ï¼Œ
            è€Œä¸æ˜¯å…¨åº“å¤‡ä»½ã€‚å¦‚éœ€å…¨åº“å¤‡ä»½ï¼Œè¯·è®¾ç½® full_db=Trueã€‚
        """
        timestamp = datetime.datetime.now().strftime('%Y%m%d%H%M%S')
        safe_tag = "".join([c for c in tag if c.isalnum() or c in ('_', '-')])
        tag_part = f"_{safe_tag}" if safe_tag else ""

        filename = f"{timestamp}{tag_part}.sql"
        filepath = self.backup_dir / filename

        # [Fix] Auto-detect binary path
        mysqldump_bin = self._find_binary('mysqldump')
        
        # æž„å»ºå‘½ä»¤
        cmd = [mysqldump_bin, '-h', self.host, '-P', str(self.port), '-u', self.user, f'-p{self.password}',
               f'--result-file={filepath}', self.db_name]
        
        # ç¡®å®šå¤‡ä»½èŒƒå›´
        if full_db:
            # å…¨åº“å¤‡ä»½ - ä¸æŒ‡å®šè¡¨
            backup_scope = "å…¨åº“"
        elif tables:
            # ä½¿ç”¨æŒ‡å®šçš„è¡¨åˆ—è¡¨
            cmd.extend(tables)
            backup_scope = f"{len(tables)} è¡¨"
        else:
            # é»˜è®¤å¤‡ä»½æ ¸å¿ƒè¡¨ (25 ä¸ª in_ è¡¨)
            cmd.extend(CORE_TABLES)
            backup_scope = f"æ ¸å¿ƒè¡¨ ({len(CORE_TABLES)})"
        
        if task_key: self._update_progress(task_key, 10, "æ­£åœ¨å¯¼å‡ºæ•°æ®...")

        try:
            res = subprocess.run(cmd, capture_output=True, text=True)
            
            if res.returncode == 0:
                if task_key: self._update_progress(task_key, 100, "å¤‡ä»½å®Œæˆ")
                size_kb = os.path.getsize(filepath) / 1024
                    
                self.audit_logger.info(f"Created Backup: {tag}", 
                                     extra={"user": get_current_user(), "action": "BACKUP_CREATE", 
                                            "target": backup_scope})
                return True, f"å¤‡ä»½æˆåŠŸ ({backup_scope}): {size_kb:.1f} KB"
            
            if filepath.exists(): os.remove(filepath)
            
            if "No such file" in str(res.stderr) and 'mysqldump' in str(res.stderr):
                 return False, "å¤‡ä»½å¤±è´¥: æ‰¾ä¸åˆ° mysqldump (è¯·è”ç³»è¿ç»´å®‰è£… MySQL Client)"
                 
            return False, f"å¤‡ä»½å¤±è´¥: {res.stderr}"
        except FileNotFoundError:
             return False, "å¤‡ä»½å¤±è´¥: ç³»ç»Ÿæœªå®‰è£… mysqldump"
        except Exception as e:
            return False, str(e)


    def restore_backup_with_progress(self, filename: str, callback=None, task_key: str = None) -> Tuple[bool, str]:
        """
        Restores the specific tables from the backup file.
        Since the backup only contains Data_Clean_Log and Data_Inventory, 
        running mysql < file.sql will only affect those tables.
        """
        filepath = self.backup_dir / filename
        if not filepath.exists(): return False, "æ–‡ä»¶ä¸å­˜åœ¨"

        # [ISO] Audit Log (Attempt)
        self.audit_logger.warning(f"Restore Requested: {filename}", 
                                extra={"user": get_current_user(), "action": "BACKUP_RESTORE_ATTEMPT", "target": filename})
        # Check if rollback support is needed (User request implies logging updates)
        # For restore, it's a full overwrite of those tables usually.

        # [Fix] Auto-detect binary path
        mysql_bin = self._find_binary('mysql')

        cmd = [mysql_bin, '-h', self.host, '-P', str(self.port), '-u', self.user, f'-p{self.password}', self.db_name]
        try:
            file_size = os.path.getsize(filepath)
            bytes_read = 0
            proc = subprocess.Popen(cmd, stdin=subprocess.PIPE, stderr=subprocess.PIPE)

            with open(filepath, 'rb') as f:
                while True:
                    chunk = f.read(1024 * 1024)
                    if not chunk: break
                    proc.stdin.write(chunk)
                    proc.stdin.flush()
                    bytes_read += len(chunk)
                    progress = bytes_read / file_size if file_size > 0 else 0
                    if callback: callback(progress)
                    if task_key: self._update_progress(task_key, int(progress * 100), "æ­£åœ¨è¿˜åŽŸæ•°æ®...")

            proc.stdin.close()
            proc.wait()

            if proc.returncode == 0:
                if callback: callback(1.0)
                if task_key: self._update_progress(task_key, 100, "è¿˜åŽŸæˆåŠŸ")
                # [ISO] Audit Log (Success)
                self.audit_logger.critical(f"Restore Successful", 
                                         extra={"user": get_current_user(), "action": "BACKUP_RESTORE_SUCCESS", "target": "Data_Clean_Log, Data_Inventory"})
                return True, "è¿˜åŽŸæˆåŠŸ"
            return False, proc.stderr.read().decode()
        except Exception as e:
            return False, str(e)

    def delete_backup(self, filename: str) -> Tuple[bool, str]:
        try:
            p = self.backup_dir / filename
            if p.exists(): 
                os.remove(p)
                # [ISO] Audit Log
                self.audit_logger.warning(f"Deleted Backup", 
                                        extra={"user": get_current_user(), "action": "BACKUP_DELETE", "target": filename})
                return True, "å·²åˆ é™¤"
            return False, "æ–‡ä»¶ä¸å­˜åœ¨"
        except Exception as e:
            return False, str(e)
            
    def delete_batch_backups(self, filenames: List[str]) -> Tuple[int, int, List[str]]:
        """
        Batch delete backups.
        Returns: (success_count, fail_count, update_messages)
        """
        success = 0
        fail = 0
        errors = []
        
        for fname in filenames:
            ok, msg = self.delete_backup(fname)
            if ok:
                success += 1
            else:
                fail += 1
                errors.append(f"{fname}: {msg}")
                
        self.audit_logger.info(f"Batch Delete Result: {success} Success, {fail} Fail", 
                             extra={"user": get_current_user(), "action": "BACKUP_BATCH_DELETE"})
        return success, fail, errors

    # --- Data Deletion Logic (Strict ISO Scope) ---
    def count_business_data_by_range(self, start_date: datetime.date, end_date: datetime.date) -> dict:
        """
        ç»Ÿè®¡æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„å¯æ¸…ç†æ•°æ®æ•°é‡ï¼ˆè„±æ•è¿”å›žï¼‰ã€‚
        ç”¨äºŽæ¸…æ´—å‘å¯¼ Step 2 çš„é¢„è§ˆéªŒè¯ã€‚
        
        Returns: {
            'sales_count': int,      # Data_Clean_Log è¡Œæ•°
            'inventory_count': int,  # Data_Inventory åˆ—æ•°
            'has_data': bool
        }
        """
        start_str = start_date.strftime("%Y-%m-%d")
        end_str = end_date.strftime("%Y-%m-%d")
        
        result = {
            'sales_count': 0,
            'inventory_count': 0,
            'has_data': False
        }
        
        try:
            with self.db.atomic_transaction() as conn:
                # 1. Count Data_Clean_Log rows
                tbl_clean = "Data_Clean_Log"
                if conn.execute(text(f"SHOW TABLES LIKE '{tbl_clean}'")).first():
                    cols = [r[0] for r in conn.execute(text(f"SHOW COLUMNS FROM `{tbl_clean}`")).fetchall()]
                    target_col = next((c for c in cols if c.lower() == 'order date'), None)
                    
                    if target_col:
                        count_sql = text(f"SELECT COUNT(*) FROM `{tbl_clean}` WHERE `{target_col}` >= :s AND `{target_col}` <= :e")
                        row = conn.execute(count_sql, {"s": start_str, "e": end_str}).fetchone()
                        result['sales_count'] = row[0] if row else 0
                
                # 2. Count Data_Inventory columns
                tbl_inv = "Data_Inventory"
                if conn.execute(text(f"SHOW TABLES LIKE '{tbl_inv}'")).first():
                    inv_cols = [r[0] for r in conn.execute(text(f"SHOW COLUMNS FROM `{tbl_inv}`")).fetchall()]
                    col_count = 0
                    for col in inv_cols:
                        try:
                            if len(col) == 10 and col[4] == '-' and col[7] == '-':
                                if start_str <= col <= end_str:
                                    col_count += 1
                        except:
                            pass
                    result['inventory_count'] = col_count
                
                result['has_data'] = (result['sales_count'] > 0) or (result['inventory_count'] > 0)
                
        except Exception as e:
            self.logger.error(f"Count business data failed: {e}")
            # è¿”å›ž 0 ä½†ä¸æš´éœ²é”™è¯¯ç»†èŠ‚
            
        return result
    
    def delete_business_data_by_range(self, start_date: datetime.date, end_date: datetime.date, reason: str) -> Tuple[
        bool, str]:
        """
        Strictly deletes data from Data_Clean_Log (Row-based) and Data_Inventory (Column-based)
        """
        user = get_current_user()
        start_str = start_date.strftime("%Y-%m-%d")
        end_str = end_date.strftime("%Y-%m-%d")

        audit_msg = f"{IMMUTABLE_MARKER} æ•°æ®æ¸…ç†è¯·æ±‚ | Range: {start_str} to {end_str} | Reason: {reason}"
        self.audit_logger.critical(audit_msg, extra={"user": user, "action": "DATA_DELETION", "table": "Data_Clean_Log, Data_Inventory"})

        log_lines = []
        
        try:
            with self.db.atomic_transaction() as conn:
                # 1. Data_Clean_Log: Delete by 'order date' row
                tbl_clean = "Data_Clean_Log"
                row_count = 0
                if conn.execute(text(f"SHOW TABLES LIKE '{tbl_clean}'")).first():
                     # Assumes 'order date' is the column as per user spec
                     # Check if column exists, if not try 'Order Date' or others? 
                     # User said: "ç¬¬ä¸€åˆ—order dateçš„å€¼ä¸ºè¯¥è¡Œè®°å½•çš„æ—¶é—´æ ‡ç­¾"
                     cols = [r[0] for r in conn.execute(text(f"SHOW COLUMNS FROM `{tbl_clean}`")).fetchall()]
                     # Find 'order date' case insensitive
                     target_col = next((c for c in cols if c.lower() == 'order date'), None)
                     
                     if target_col:
                        del_sql = text(f"DELETE FROM `{tbl_clean}` WHERE `{target_col}` >= :s AND `{target_col}` <= :e")
                        res = conn.execute(del_sql, {"s": start_str, "e": end_str})
                        row_count = res.rowcount
                        log_lines.append(f" äº¤æ˜“æ•°æ®: åˆ é™¤äº† {row_count} è¡Œ (æŒ‰æ—¥æœŸèŒƒå›´)")
                     else:
                        log_lines.append(f" {tbl_clean}: æœªæ‰¾åˆ° 'order date' åˆ—")
                
                # 2. Data_Inventory: Delete by Column Name (Date)
                tbl_inv = "Data_Inventory"
                col_count = 0
                if conn.execute(text(f"SHOW TABLES LIKE '{tbl_inv}'")).first():
                    inv_cols = [r[0] for r in conn.execute(text(f"SHOW COLUMNS FROM `{tbl_inv}`")).fetchall()]
                    cols_to_drop = []
                    for col in inv_cols:
                        # User said: "åˆ—åä¸ºè¯¥åˆ—æ•°æ®çš„æ—¶é—´æ ‡ç­¾"
                        # Check if column name parses to date in range
                        # Attempt standard ISO format 2025-01-01
                        try:
                            # Heuristic: YYYY-MM-DD
                            if len(col) == 10 and col[4] == '-' and col[7] == '-':
                                if start_str <= col <= end_str:
                                    cols_to_drop.append(col)
                        except:
                            pass

                    if cols_to_drop:
                        drop_parts = [f"DROP COLUMN `{c}`" for c in cols_to_drop]
                        alter_sql = f"ALTER TABLE `{tbl_inv}` " + ", ".join(drop_parts)
                        conn.execute(text(alter_sql))
                        col_count = len(cols_to_drop)
                        log_lines.append(f" åº“å­˜æ•°æ®: åˆ é™¤äº† {col_count} ä¸ªæ—¥æœŸåˆ— (æŒ‰è¿‡æœŸåˆ—åˆ é™¤)")
                    else:
                        log_lines.append(f" åº“å­˜æ•°æ®: æœªå‘çŽ°èŒƒå›´å†…çš„è¿‡æœŸæ•°æ®")

            final_msg = "\n".join(log_lines)
            self.logger.warning(f"æ•°æ®æ¸…ç†å®Œæˆ:\n{final_msg}")
            
            # Additional Audit for Result
            self.audit_logger.critical(f"{IMMUTABLE_MARKER} æ¸…ç†ç»“æžœ: Clean_Log_Rows={row_count}, Inv_Cols={col_count}",
                                       extra={"user": user, "action": "DATA_DELETION_RESULT"})

            return True, final_msg
        except Exception as e:
            self.logger.error(f"æ•°æ®æ¸…ç†å¤±è´¥: {e}")
            return False, str(e)